{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soap import * \n",
    "import os\n",
    "\n",
    "from model import MOFSetTransformerTrainer, MOFDataManager, ModifiedAggregateFunction\n",
    "\n",
    "# training_pipeline.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.nn.aggr import SetTransformerAggregation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from typing import Tuple, Dict, List, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import SetTransformer\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model  \u001b[38;5;241m=\u001b[39m \u001b[43mSetTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m484\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_inds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_hidden\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1355\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1353\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 915 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/nn/modules/module.py:942\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 942\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1341\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1336\u001b[0m             device,\n\u001b[1;32m   1337\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1338\u001b[0m             non_blocking,\n\u001b[1;32m   1339\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1340\u001b[0m         )\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/cuda/__init__.py:372\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    371\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 372\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    376\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "model  = SetTransformer(dim_input = 484, num_outputs = 1, dim_output = 1, num_inds=32, dim_hidden=256, num_heads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimized_models_fast60.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/serialization.py:1516\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m   1515\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1516\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1523\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1524\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/serialization.py:2114\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   2112\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[1;32m   2113\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 2114\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2115\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2117\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m~/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/_weights_only_unpickler.py:532\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mserialization\u001b[38;5;241m.\u001b[39m_maybe_decode_ascii(pid[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     ):\n\u001b[1;32m    529\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[1;32m    530\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    531\u001b[0m         )\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[38;5;241m0\u001b[39m], LONG_BINGET[\u001b[38;5;241m0\u001b[39m]]:\n\u001b[1;32m    534\u001b[0m     idx \u001b[38;5;241m=\u001b[39m (read(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m BINGET[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m, read(\u001b[38;5;241m4\u001b[39m)))[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/serialization.py:2078\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   2076\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2077\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 2078\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2079\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2080\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/serialization.py:2044\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_guards\u001b[38;5;241m.\u001b[39mdetect_fake_mode(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2044\u001b[0m     wrap_storage \u001b[38;5;241m=\u001b[39m \u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2045\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2046\u001b[0m     storage\u001b[38;5;241m.\u001b[39m_fake_device \u001b[38;5;241m=\u001b[39m location\n",
      "File \u001b[0;32m~/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/serialization.py:698\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 698\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    700\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/serialization.py:636\u001b[0m, in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    634\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[0;32m--> 636\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/serialization.py:605\u001b[0m, in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    603\u001b[0m     device_index \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_available\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    607\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.is_available() is False. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    609\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    610\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    611\u001b[0m     )\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_count\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    613\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m device_module\u001b[38;5;241m.\u001b[39mdevice_count()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "torch.load(\"optimized_models_fast60.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimized_models_fast60.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(\"optimized_models_fast60.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"../CIF_files\"\n",
    "filenames = os.listdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading targets from: ../id_labels.csv\n",
      "CSV columns: ['id', 'label']\n",
      "CSV shape: (3089, 2)\n",
      "First few rows:\n",
      "                                               id      label\n",
      "0  DB5-hypotheticalMOF_17652_0_0_1_21_9_7_repeat   13.791591\n",
      "1             DB0-m2_o8_o23_f0_pcu.sym.80_repeat    3.786996\n",
      "2         DB0-m29_o90_o1500_f0_pts.sym.31_repeat    9.382537\n",
      "3             DB0-m3_o48_o25_f0_fsc.sym.3_repeat   11.650365\n",
      "4             DB0-m2_o1_o9_f0_nbo.sym.104_repeat    1.412915\n",
      "Using 'id' column for filenames and 'label' column for targets\n",
      "Loaded 3089 target values\n",
      "Target range: 0.006 to 37.706\n",
      "Example filename mappings:\n",
      "  'DB5-hypotheticalMOF_17652_0_0_1_21_9_7_repeat.cif' -> 13.79159108\n",
      "  'DB0-m2_o8_o23_f0_pcu.sym.80_repeat.cif' -> 3.786995708\n",
      "  'DB0-m29_o90_o1500_f0_pts.sym.31_repeat.cif' -> 9.382537337\n",
      "Total CIF files found: 3089\n",
      "CIF files with targets: 3089\n",
      "Data split:\n",
      "  Train files: 2471 (80.0%)\n",
      "  Test files: 618 (20.0%)\n",
      "âœ“ Verified no data leakage between splits\n"
     ]
    }
   ],
   "source": [
    "data_manager = MOFDataManager(\n",
    "        folder_path='../CIF_files',  # Adjust path as needed\n",
    "        target_csv=\"../id_labels.csv\",  # Your target file\n",
    "        val_size=0.0,   # 20% for validation\n",
    "        test_size=0.2,  # 20% for test (60% remains for training)\n",
    "        random_state=42\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<model.MOFDataManager at 0x1555337a4100>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MOFSetTransformerTrainer(\n",
    "        data_manager=data_manager,\n",
    "        aggregator_params={\n",
    "            'num_seed_points': 1,        # Current: 3, try more seeds\n",
    "            'num_encoder_blocks': 1,     # Current: 2, try more layers\n",
    "            'num_decoder_blocks': 1,     # Current: 1, try more\n",
    "            'heads': 4,                  # Current: 4, try more attention heads\n",
    "            'dropout': 0.3,              # Current: 0.1, try higher dropout\n",
    "        },\n",
    "        loss_metric='mae' \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining all unique SOAP columns across ENTIRE dataset...\n",
      "Processing ALL 3089 files to find unique columns...\n",
      "Processed 0/3089 files, found 0 unique columns so far...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100/3089 files, found 188 unique columns so far...\n",
      "Processed 200/3089 files, found 236 unique columns so far...\n",
      "Processed 300/3089 files, found 282 unique columns so far...\n",
      "Processed 400/3089 files, found 298 unique columns so far...\n",
      "Processed 500/3089 files, found 300 unique columns so far...\n",
      "Processed 600/3089 files, found 312 unique columns so far...\n",
      "Processed 700/3089 files, found 318 unique columns so far...\n",
      "Processed 800/3089 files, found 332 unique columns so far...\n",
      "Processed 900/3089 files, found 332 unique columns so far...\n",
      "Processed 1000/3089 files, found 352 unique columns so far...\n",
      "Processed 1100/3089 files, found 354 unique columns so far...\n",
      "Processed 1200/3089 files, found 372 unique columns so far...\n",
      "Processed 1300/3089 files, found 386 unique columns so far...\n",
      "Processed 1400/3089 files, found 394 unique columns so far...\n",
      "Processed 1500/3089 files, found 420 unique columns so far...\n",
      "Processed 1600/3089 files, found 424 unique columns so far...\n",
      "Processed 1700/3089 files, found 424 unique columns so far...\n",
      "Processed 1800/3089 files, found 450 unique columns so far...\n",
      "Processed 1900/3089 files, found 450 unique columns so far...\n",
      "Processed 2000/3089 files, found 450 unique columns so far...\n",
      "Processed 2100/3089 files, found 452 unique columns so far...\n",
      "Processed 2200/3089 files, found 456 unique columns so far...\n",
      "Processed 2300/3089 files, found 458 unique columns so far...\n",
      "Processed 2400/3089 files, found 464 unique columns so far...\n",
      "Processed 2500/3089 files, found 466 unique columns so far...\n",
      "Processed 2600/3089 files, found 466 unique columns so far...\n",
      "Processed 2700/3089 files, found 470 unique columns so far...\n",
      "Processed 2800/3089 files, found 472 unique columns so far...\n",
      "Processed 2900/3089 files, found 482 unique columns so far...\n",
      "Processed 3000/3089 files, found 484 unique columns so far...\n",
      "Found 484 unique SOAP columns across ALL files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Ag-Ag_1',\n",
       " 'Ag-Ag_2',\n",
       " 'Ag-C_1',\n",
       " 'Ag-C_2',\n",
       " 'Ag-Cr_1',\n",
       " 'Ag-Cr_2',\n",
       " 'Ag-O_1',\n",
       " 'Ag-O_2',\n",
       " 'Al-Al_1',\n",
       " 'Al-Al_2',\n",
       " 'Al-C_1',\n",
       " 'Al-C_2',\n",
       " 'Al-F_1',\n",
       " 'Al-F_2',\n",
       " 'Al-H_1',\n",
       " 'Al-H_2',\n",
       " 'Al-N_1',\n",
       " 'Al-N_2',\n",
       " 'Al-O_1',\n",
       " 'Al-O_2',\n",
       " 'Al-P_1',\n",
       " 'Al-P_2',\n",
       " 'Al-S_1',\n",
       " 'Al-S_2',\n",
       " 'Br-Br_1',\n",
       " 'Br-Br_2',\n",
       " 'Br-C_1',\n",
       " 'Br-C_2',\n",
       " 'Br-Cd_1',\n",
       " 'Br-Cd_2',\n",
       " 'Br-Ce_1',\n",
       " 'Br-Ce_2',\n",
       " 'Br-Cl_1',\n",
       " 'Br-Cl_2',\n",
       " 'Br-Co_1',\n",
       " 'Br-Co_2',\n",
       " 'Br-Cu_1',\n",
       " 'Br-Cu_2',\n",
       " 'Br-F_1',\n",
       " 'Br-F_2',\n",
       " 'Br-Fe_1',\n",
       " 'Br-Fe_2',\n",
       " 'Br-H_1',\n",
       " 'Br-H_2',\n",
       " 'Br-La_1',\n",
       " 'Br-La_2',\n",
       " 'Br-Li_1',\n",
       " 'Br-Li_2',\n",
       " 'Br-N_1',\n",
       " 'Br-N_2',\n",
       " 'Br-O_1',\n",
       " 'Br-O_2',\n",
       " 'Br-Pd_1',\n",
       " 'Br-Pd_2',\n",
       " 'Br-S_1',\n",
       " 'Br-S_2',\n",
       " 'Br-Si_1',\n",
       " 'Br-Si_2',\n",
       " 'Br-Ti_1',\n",
       " 'Br-Ti_2',\n",
       " 'Br-V_1',\n",
       " 'Br-V_2',\n",
       " 'Br-Zn_1',\n",
       " 'Br-Zn_2',\n",
       " 'C-C_1',\n",
       " 'C-C_2',\n",
       " 'C-Ca_1',\n",
       " 'C-Ca_2',\n",
       " 'C-Cd_1',\n",
       " 'C-Cd_2',\n",
       " 'C-Ce_1',\n",
       " 'C-Ce_2',\n",
       " 'C-Cl_1',\n",
       " 'C-Cl_2',\n",
       " 'C-Co_1',\n",
       " 'C-Co_2',\n",
       " 'C-Cr_1',\n",
       " 'C-Cr_2',\n",
       " 'C-Cu_1',\n",
       " 'C-Cu_2',\n",
       " 'C-Dy_1',\n",
       " 'C-Dy_2',\n",
       " 'C-Er_1',\n",
       " 'C-Er_2',\n",
       " 'C-Eu_1',\n",
       " 'C-Eu_2',\n",
       " 'C-F_1',\n",
       " 'C-F_2',\n",
       " 'C-Fe_1',\n",
       " 'C-Fe_2',\n",
       " 'C-Gd_1',\n",
       " 'C-Gd_2',\n",
       " 'C-H_1',\n",
       " 'C-H_2',\n",
       " 'C-I_1',\n",
       " 'C-I_2',\n",
       " 'C-In_1',\n",
       " 'C-In_2',\n",
       " 'C-La_1',\n",
       " 'C-La_2',\n",
       " 'C-Li_1',\n",
       " 'C-Li_2',\n",
       " 'C-Mg_1',\n",
       " 'C-Mg_2',\n",
       " 'C-Mn_1',\n",
       " 'C-Mn_2',\n",
       " 'C-N_1',\n",
       " 'C-N_2',\n",
       " 'C-Nd_1',\n",
       " 'C-Nd_2',\n",
       " 'C-Ni_1',\n",
       " 'C-Ni_2',\n",
       " 'C-O_1',\n",
       " 'C-O_2',\n",
       " 'C-Pd_1',\n",
       " 'C-Pd_2',\n",
       " 'C-S_1',\n",
       " 'C-S_2',\n",
       " 'C-Sc_1',\n",
       " 'C-Sc_2',\n",
       " 'C-Si_1',\n",
       " 'C-Si_2',\n",
       " 'C-Sm_1',\n",
       " 'C-Sm_2',\n",
       " 'C-Tb_1',\n",
       " 'C-Tb_2',\n",
       " 'C-Ti_1',\n",
       " 'C-Ti_2',\n",
       " 'C-V_1',\n",
       " 'C-V_2',\n",
       " 'C-Y_1',\n",
       " 'C-Y_2',\n",
       " 'C-Zn_1',\n",
       " 'C-Zn_2',\n",
       " 'C-Zr_1',\n",
       " 'C-Zr_2',\n",
       " 'Ca-Ca_1',\n",
       " 'Ca-Ca_2',\n",
       " 'Ca-Cd_1',\n",
       " 'Ca-Cd_2',\n",
       " 'Ca-H_1',\n",
       " 'Ca-H_2',\n",
       " 'Ca-O_1',\n",
       " 'Ca-O_2',\n",
       " 'Ca-S_1',\n",
       " 'Ca-S_2',\n",
       " 'Cd-Cd_1',\n",
       " 'Cd-Cd_2',\n",
       " 'Cd-Cl_1',\n",
       " 'Cd-Cl_2',\n",
       " 'Cd-F_1',\n",
       " 'Cd-F_2',\n",
       " 'Cd-H_1',\n",
       " 'Cd-H_2',\n",
       " 'Cd-N_1',\n",
       " 'Cd-N_2',\n",
       " 'Cd-O_1',\n",
       " 'Cd-O_2',\n",
       " 'Ce-Ce_1',\n",
       " 'Ce-Ce_2',\n",
       " 'Ce-H_1',\n",
       " 'Ce-H_2',\n",
       " 'Ce-O_1',\n",
       " 'Ce-O_2',\n",
       " 'Ce-S_1',\n",
       " 'Ce-S_2',\n",
       " 'Cl-Cl_1',\n",
       " 'Cl-Cl_2',\n",
       " 'Cl-Cu_1',\n",
       " 'Cl-Cu_2',\n",
       " 'Cl-F_1',\n",
       " 'Cl-F_2',\n",
       " 'Cl-Fe_1',\n",
       " 'Cl-Fe_2',\n",
       " 'Cl-H_1',\n",
       " 'Cl-H_2',\n",
       " 'Cl-Li_1',\n",
       " 'Cl-Li_2',\n",
       " 'Cl-Mn_1',\n",
       " 'Cl-Mn_2',\n",
       " 'Cl-N_1',\n",
       " 'Cl-N_2',\n",
       " 'Cl-O_1',\n",
       " 'Cl-O_2',\n",
       " 'Cl-Pd_1',\n",
       " 'Cl-Pd_2',\n",
       " 'Cl-S_1',\n",
       " 'Cl-S_2',\n",
       " 'Cl-Ti_1',\n",
       " 'Cl-Ti_2',\n",
       " 'Cl-V_1',\n",
       " 'Cl-V_2',\n",
       " 'Cl-Zn_1',\n",
       " 'Cl-Zn_2',\n",
       " 'Co-Co_1',\n",
       " 'Co-Co_2',\n",
       " 'Co-F_1',\n",
       " 'Co-F_2',\n",
       " 'Co-H_1',\n",
       " 'Co-H_2',\n",
       " 'Co-N_1',\n",
       " 'Co-N_2',\n",
       " 'Co-O_1',\n",
       " 'Co-O_2',\n",
       " 'Co-P_1',\n",
       " 'Co-P_2',\n",
       " 'Co-S_1',\n",
       " 'Co-S_2',\n",
       " 'Cr-Cr_1',\n",
       " 'Cr-Cr_2',\n",
       " 'Cr-H_1',\n",
       " 'Cr-H_2',\n",
       " 'Cr-Mn_1',\n",
       " 'Cr-Mn_2',\n",
       " 'Cr-N_1',\n",
       " 'Cr-N_2',\n",
       " 'Cr-O_1',\n",
       " 'Cr-O_2',\n",
       " 'Cu-Cu_1',\n",
       " 'Cu-Cu_2',\n",
       " 'Cu-F_1',\n",
       " 'Cu-F_2',\n",
       " 'Cu-H_1',\n",
       " 'Cu-H_2',\n",
       " 'Cu-I_1',\n",
       " 'Cu-I_2',\n",
       " 'Cu-Li_1',\n",
       " 'Cu-Li_2',\n",
       " 'Cu-N_1',\n",
       " 'Cu-N_2',\n",
       " 'Cu-O_1',\n",
       " 'Cu-O_2',\n",
       " 'Cu-S_1',\n",
       " 'Cu-S_2',\n",
       " 'Cu-Si_1',\n",
       " 'Cu-Si_2',\n",
       " 'Dy-Dy_1',\n",
       " 'Dy-Dy_2',\n",
       " 'Dy-H_1',\n",
       " 'Dy-H_2',\n",
       " 'Dy-N_1',\n",
       " 'Dy-N_2',\n",
       " 'Dy-O_1',\n",
       " 'Dy-O_2',\n",
       " 'Er-Er_1',\n",
       " 'Er-Er_2',\n",
       " 'Er-H_1',\n",
       " 'Er-H_2',\n",
       " 'Er-N_1',\n",
       " 'Er-N_2',\n",
       " 'Er-O_1',\n",
       " 'Er-O_2',\n",
       " 'Er-S_1',\n",
       " 'Er-S_2',\n",
       " 'Eu-Eu_1',\n",
       " 'Eu-Eu_2',\n",
       " 'Eu-H_1',\n",
       " 'Eu-H_2',\n",
       " 'Eu-N_1',\n",
       " 'Eu-N_2',\n",
       " 'Eu-O_1',\n",
       " 'Eu-O_2',\n",
       " 'F-F_1',\n",
       " 'F-F_2',\n",
       " 'F-Fe_1',\n",
       " 'F-Fe_2',\n",
       " 'F-H_1',\n",
       " 'F-H_2',\n",
       " 'F-N_1',\n",
       " 'F-N_2',\n",
       " 'F-Ni_1',\n",
       " 'F-Ni_2',\n",
       " 'F-O_1',\n",
       " 'F-O_2',\n",
       " 'F-S_1',\n",
       " 'F-S_2',\n",
       " 'F-Si_1',\n",
       " 'F-Si_2',\n",
       " 'F-Ti_1',\n",
       " 'F-Ti_2',\n",
       " 'F-V_1',\n",
       " 'F-V_2',\n",
       " 'F-Zn_1',\n",
       " 'F-Zn_2',\n",
       " 'Fe-Fe_1',\n",
       " 'Fe-Fe_2',\n",
       " 'Fe-H_1',\n",
       " 'Fe-H_2',\n",
       " 'Fe-I_1',\n",
       " 'Fe-I_2',\n",
       " 'Fe-N_1',\n",
       " 'Fe-N_2',\n",
       " 'Fe-O_1',\n",
       " 'Fe-O_2',\n",
       " 'Fe-S_1',\n",
       " 'Fe-S_2',\n",
       " 'Gd-Gd_1',\n",
       " 'Gd-Gd_2',\n",
       " 'Gd-H_1',\n",
       " 'Gd-H_2',\n",
       " 'Gd-N_1',\n",
       " 'Gd-N_2',\n",
       " 'Gd-O_1',\n",
       " 'Gd-O_2',\n",
       " 'Gd-S_1',\n",
       " 'Gd-S_2',\n",
       " 'H-H_1',\n",
       " 'H-H_2',\n",
       " 'H-I_1',\n",
       " 'H-I_2',\n",
       " 'H-In_1',\n",
       " 'H-In_2',\n",
       " 'H-La_1',\n",
       " 'H-La_2',\n",
       " 'H-Li_1',\n",
       " 'H-Li_2',\n",
       " 'H-Mg_1',\n",
       " 'H-Mg_2',\n",
       " 'H-Mn_1',\n",
       " 'H-Mn_2',\n",
       " 'H-N_1',\n",
       " 'H-N_2',\n",
       " 'H-Nd_1',\n",
       " 'H-Nd_2',\n",
       " 'H-Ni_1',\n",
       " 'H-Ni_2',\n",
       " 'H-O_1',\n",
       " 'H-O_2',\n",
       " 'H-Pd_1',\n",
       " 'H-Pd_2',\n",
       " 'H-S_1',\n",
       " 'H-S_2',\n",
       " 'H-Sc_1',\n",
       " 'H-Sc_2',\n",
       " 'H-Si_1',\n",
       " 'H-Si_2',\n",
       " 'H-Sm_1',\n",
       " 'H-Sm_2',\n",
       " 'H-Tb_1',\n",
       " 'H-Tb_2',\n",
       " 'H-Ti_1',\n",
       " 'H-Ti_2',\n",
       " 'H-V_1',\n",
       " 'H-V_2',\n",
       " 'H-Y_1',\n",
       " 'H-Y_2',\n",
       " 'H-Zn_1',\n",
       " 'H-Zn_2',\n",
       " 'H-Zr_1',\n",
       " 'H-Zr_2',\n",
       " 'I-I_1',\n",
       " 'I-I_2',\n",
       " 'I-N_1',\n",
       " 'I-N_2',\n",
       " 'I-O_1',\n",
       " 'I-O_2',\n",
       " 'I-V_1',\n",
       " 'I-V_2',\n",
       " 'I-Zn_1',\n",
       " 'I-Zn_2',\n",
       " 'In-In_1',\n",
       " 'In-In_2',\n",
       " 'In-O_1',\n",
       " 'In-O_2',\n",
       " 'La-La_1',\n",
       " 'La-La_2',\n",
       " 'La-N_1',\n",
       " 'La-N_2',\n",
       " 'La-O_1',\n",
       " 'La-O_2',\n",
       " 'Li-Li_1',\n",
       " 'Li-Li_2',\n",
       " 'Li-N_1',\n",
       " 'Li-N_2',\n",
       " 'Li-O_1',\n",
       " 'Li-O_2',\n",
       " 'Li-S_1',\n",
       " 'Li-S_2',\n",
       " 'Li-Zn_1',\n",
       " 'Li-Zn_2',\n",
       " 'Mg-Mg_1',\n",
       " 'Mg-Mg_2',\n",
       " 'Mg-N_1',\n",
       " 'Mg-N_2',\n",
       " 'Mg-O_1',\n",
       " 'Mg-O_2',\n",
       " 'Mg-Si_1',\n",
       " 'Mg-Si_2',\n",
       " 'Mn-Mn_1',\n",
       " 'Mn-Mn_2',\n",
       " 'Mn-N_1',\n",
       " 'Mn-N_2',\n",
       " 'Mn-O_1',\n",
       " 'Mn-O_2',\n",
       " 'Mn-S_1',\n",
       " 'Mn-S_2',\n",
       " 'N-N_1',\n",
       " 'N-N_2',\n",
       " 'N-Nd_1',\n",
       " 'N-Nd_2',\n",
       " 'N-Ni_1',\n",
       " 'N-Ni_2',\n",
       " 'N-O_1',\n",
       " 'N-O_2',\n",
       " 'N-Pd_1',\n",
       " 'N-Pd_2',\n",
       " 'N-S_1',\n",
       " 'N-S_2',\n",
       " 'N-Si_1',\n",
       " 'N-Si_2',\n",
       " 'N-Tb_1',\n",
       " 'N-Tb_2',\n",
       " 'N-Ti_1',\n",
       " 'N-Ti_2',\n",
       " 'N-V_1',\n",
       " 'N-V_2',\n",
       " 'N-Zn_1',\n",
       " 'N-Zn_2',\n",
       " 'N-Zr_1',\n",
       " 'N-Zr_2',\n",
       " 'Nd-Nd_1',\n",
       " 'Nd-Nd_2',\n",
       " 'Nd-O_1',\n",
       " 'Nd-O_2',\n",
       " 'Ni-Ni_1',\n",
       " 'Ni-Ni_2',\n",
       " 'Ni-O_1',\n",
       " 'Ni-O_2',\n",
       " 'Ni-S_1',\n",
       " 'Ni-S_2',\n",
       " 'O-O_1',\n",
       " 'O-O_2',\n",
       " 'O-P_1',\n",
       " 'O-P_2',\n",
       " 'O-Pd_1',\n",
       " 'O-Pd_2',\n",
       " 'O-S_1',\n",
       " 'O-S_2',\n",
       " 'O-Sc_1',\n",
       " 'O-Sc_2',\n",
       " 'O-Si_1',\n",
       " 'O-Si_2',\n",
       " 'O-Sm_1',\n",
       " 'O-Sm_2',\n",
       " 'O-Tb_1',\n",
       " 'O-Tb_2',\n",
       " 'O-Ti_1',\n",
       " 'O-Ti_2',\n",
       " 'O-V_1',\n",
       " 'O-V_2',\n",
       " 'O-Y_1',\n",
       " 'O-Y_2',\n",
       " 'O-Zn_1',\n",
       " 'O-Zn_2',\n",
       " 'O-Zr_1',\n",
       " 'O-Zr_2',\n",
       " 'P-P_1',\n",
       " 'P-P_2',\n",
       " 'Pd-Pd_1',\n",
       " 'Pd-Pd_2',\n",
       " 'S-S_1',\n",
       " 'S-S_2',\n",
       " 'S-V_1',\n",
       " 'S-V_2',\n",
       " 'S-Zn_1',\n",
       " 'S-Zn_2',\n",
       " 'Sc-Sc_1',\n",
       " 'Sc-Sc_2',\n",
       " 'Si-Si_1',\n",
       " 'Si-Si_2',\n",
       " 'Sm-Sm_1',\n",
       " 'Sm-Sm_2',\n",
       " 'Tb-Tb_1',\n",
       " 'Tb-Tb_2',\n",
       " 'Ti-Ti_1',\n",
       " 'Ti-Ti_2',\n",
       " 'V-V_1',\n",
       " 'V-V_2',\n",
       " 'Y-Y_1',\n",
       " 'Y-Y_2',\n",
       " 'Zn-Zn_1',\n",
       " 'Zn-Zn_2',\n",
       " 'Zr-Zr_1',\n",
       " 'Zr-Zr_2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.determine_all_soap_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized SetTransformerAggregation with:\n",
      "  SOAP dimension: 484\n",
      "  Unique columns: 484\n",
      "  channels: 484\n",
      "  num_seed_points: 1\n",
      "  num_encoder_blocks: 1\n",
      "  num_decoder_blocks: 1\n",
      "  heads: 4\n",
      "  concat: True\n",
      "  layer_norm: True\n",
      "  dropout: 0.3\n",
      "Initialized prediction head with input dim: 484\n",
      "Starting end-to-end training for 5 epochs...\n",
      "Train files: 2471, Test files: 618\n",
      "Using batch size: 100\n"
     ]
    }
   ],
   "source": [
    " results = trainer.train(\n",
    "        epochs=5,\n",
    "        learning_rate=0.01,  # Lower LR for end-to-end training\n",
    "        patience=100,\n",
    "        batch_size=100,      # Process 100 files per epoch\n",
    "        verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soap_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
