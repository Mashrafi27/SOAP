wandb: Appending key for api.wandb.ai to your netrc file: /home/mmm9886/.netrc
wandb: Currently logged in as: mashrafimonon (mashrafimonon-new-york-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /scratch/mmm9886/Chignolin_Trajectory/SOAP_research/Final_Attention/wandb/run-20250816_145022-aqpy7h9z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-pond-47
wandb: â­ï¸ View project at https://wandb.ai/mashrafimonon-new-york-university/mof-settransformer
wandb: ðŸš€ View run at https://wandb.ai/mashrafimonon-new-york-university/mof-settransformer/runs/aqpy7h9z
Using device: cuda
=== MOF SetTransformer Training Pipeline ===

Loading targets from: ../id_labels.csv
CSV columns: ['id', 'label']
CSV shape: (3089, 2)
First few rows:
                                               id      label
0  DB5-hypotheticalMOF_17652_0_0_1_21_9_7_repeat   13.791591
1             DB0-m2_o8_o23_f0_pcu.sym.80_repeat    3.786996
2         DB0-m29_o90_o1500_f0_pts.sym.31_repeat    9.382537
3             DB0-m3_o48_o25_f0_fsc.sym.3_repeat   11.650365
4             DB0-m2_o1_o9_f0_nbo.sym.104_repeat    1.412915
Using 'id' column for filenames and 'label' column for targets
Loaded 3089 target values
Target range: 0.006 to 37.706
Example filename mappings:
  'DB5-hypotheticalMOF_17652_0_0_1_21_9_7_repeat.cif' -> 13.79159108
  'DB0-m2_o8_o23_f0_pcu.sym.80_repeat.cif' -> 3.786995708
  'DB0-m29_o90_o1500_f0_pts.sym.31_repeat.cif' -> 9.382537337
Total CIF files found: 3089
CIF files with targets: 3089
Data split:
  Train files: 2471 (80.0%)
  Test files: 618 (20.0%)
âœ“ Verified no data leakage between splits
Determining all unique SOAP columns across ENTIRE dataset...
Processing ALL 3089 files to find unique columns...
Processed 0/3089 files, found 0 unique columns so far...
Processed 100/3089 files, found 188 unique columns so far...
Processed 200/3089 files, found 236 unique columns so far...
Processed 300/3089 files, found 282 unique columns so far...
Processed 400/3089 files, found 298 unique columns so far...
Processed 500/3089 files, found 300 unique columns so far...
Processed 600/3089 files, found 312 unique columns so far...
Processed 700/3089 files, found 318 unique columns so far...
Processed 800/3089 files, found 332 unique columns so far...
Processed 900/3089 files, found 332 unique columns so far...
Processed 1000/3089 files, found 352 unique columns so far...
Processed 1100/3089 files, found 354 unique columns so far...
Processed 1200/3089 files, found 372 unique columns so far...
Processed 1300/3089 files, found 386 unique columns so far...
Processed 1400/3089 files, found 394 unique columns so far...
Processed 1500/3089 files, found 420 unique columns so far...
Processed 1600/3089 files, found 424 unique columns so far...
Processed 1700/3089 files, found 424 unique columns so far...
Processed 1800/3089 files, found 450 unique columns so far...
Processed 1900/3089 files, found 450 unique columns so far...
Processed 2000/3089 files, found 450 unique columns so far...
Processed 2100/3089 files, found 452 unique columns so far...
Processed 2200/3089 files, found 456 unique columns so far...
Processed 2300/3089 files, found 458 unique columns so far...
Processed 2400/3089 files, found 464 unique columns so far...
Processed 2500/3089 files, found 466 unique columns so far...
Processed 2600/3089 files, found 466 unique columns so far...
Processed 2700/3089 files, found 470 unique columns so far...
Processed 2800/3089 files, found 472 unique columns so far...
Processed 2900/3089 files, found 482 unique columns so far...
Processed 3000/3089 files, found 484 unique columns so far...
Found 484 unique SOAP columns across ALL files
Traceback (most recent call last):
  File "/scratch/mmm9886/Chignolin_Trajectory/SOAP_research/Final_Attention/model.py", line 1062, in <module>
    trainer, results = main()
  File "/scratch/mmm9886/Chignolin_Trajectory/SOAP_research/Final_Attention/model.py", line 1043, in main
    results = trainer.train(
  File "/scratch/mmm9886/Chignolin_Trajectory/SOAP_research/Final_Attention/model.py", line 697, in train
    self._initialize_models()
  File "/scratch/mmm9886/Chignolin_Trajectory/SOAP_research/Final_Attention/model.py", line 610, in _initialize_models
    self.encoder_decoder.load_state_dict(torch.load("optimized_models_fast60.pth")).to(device)
  File "/home/mmm9886/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for SetTransformer:
	Missing key(s) in state_dict: "enc.0.I", "enc.0.mab0.fc_q.weight", "enc.0.mab0.fc_q.bias", "enc.0.mab0.fc_k.weight", "enc.0.mab0.fc_k.bias", "enc.0.mab0.fc_v.weight", "enc.0.mab0.fc_v.bias", "enc.0.mab0.fc_o.weight", "enc.0.mab0.fc_o.bias", "enc.0.mab1.fc_q.weight", "enc.0.mab1.fc_q.bias", "enc.0.mab1.fc_k.weight", "enc.0.mab1.fc_k.bias", "enc.0.mab1.fc_v.weight", "enc.0.mab1.fc_v.bias", "enc.0.mab1.fc_o.weight", "enc.0.mab1.fc_o.bias", "enc.1.I", "enc.1.mab0.fc_q.weight", "enc.1.mab0.fc_q.bias", "enc.1.mab0.fc_k.weight", "enc.1.mab0.fc_k.bias", "enc.1.mab0.fc_v.weight", "enc.1.mab0.fc_v.bias", "enc.1.mab0.fc_o.weight", "enc.1.mab0.fc_o.bias", "enc.1.mab1.fc_q.weight", "enc.1.mab1.fc_q.bias", "enc.1.mab1.fc_k.weight", "enc.1.mab1.fc_k.bias", "enc.1.mab1.fc_v.weight", "enc.1.mab1.fc_v.bias", "enc.1.mab1.fc_o.weight", "enc.1.mab1.fc_o.bias", "dec.0.S", "dec.0.mab.fc_q.weight", "dec.0.mab.fc_q.bias", "dec.0.mab.fc_k.weight", "dec.0.mab.fc_k.bias", "dec.0.mab.fc_v.weight", "dec.0.mab.fc_v.bias", "dec.0.mab.fc_o.weight", "dec.0.mab.fc_o.bias", "dec.1.mab.fc_q.weight", "dec.1.mab.fc_q.bias", "dec.1.mab.fc_k.weight", "dec.1.mab.fc_k.bias", "dec.1.mab.fc_v.weight", "dec.1.mab.fc_v.bias", "dec.1.mab.fc_o.weight", "dec.1.mab.fc_o.bias", "dec.2.mab.fc_q.weight", "dec.2.mab.fc_q.bias", "dec.2.mab.fc_k.weight", "dec.2.mab.fc_k.bias", "dec.2.mab.fc_v.weight", "dec.2.mab.fc_v.bias", "dec.2.mab.fc_o.weight", "dec.2.mab.fc_o.bias", "dec.3.weight", "dec.3.bias". 
	Unexpected key(s) in state_dict: "encoder_decoder". 
Traceback (most recent call last):
  File "/scratch/mmm9886/Chignolin_Trajectory/SOAP_research/Final_Attention/model.py", line 1062, in <module>
    trainer, results = main()
  File "/scratch/mmm9886/Chignolin_Trajectory/SOAP_research/Final_Attention/model.py", line 1043, in main
    results = trainer.train(
  File "/scratch/mmm9886/Chignolin_Trajectory/SOAP_research/Final_Attention/model.py", line 697, in train
    self._initialize_models()
  File "/scratch/mmm9886/Chignolin_Trajectory/SOAP_research/Final_Attention/model.py", line 610, in _initialize_models
    self.encoder_decoder.load_state_dict(torch.load("optimized_models_fast60.pth")).to(device)
  File "/home/mmm9886/.conda/envs/soap_analysis/lib/python3.9/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for SetTransformer:
	Missing key(s) in state_dict: "enc.0.I", "enc.0.mab0.fc_q.weight", "enc.0.mab0.fc_q.bias", "enc.0.mab0.fc_k.weight", "enc.0.mab0.fc_k.bias", "enc.0.mab0.fc_v.weight", "enc.0.mab0.fc_v.bias", "enc.0.mab0.fc_o.weight", "enc.0.mab0.fc_o.bias", "enc.0.mab1.fc_q.weight", "enc.0.mab1.fc_q.bias", "enc.0.mab1.fc_k.weight", "enc.0.mab1.fc_k.bias", "enc.0.mab1.fc_v.weight", "enc.0.mab1.fc_v.bias", "enc.0.mab1.fc_o.weight", "enc.0.mab1.fc_o.bias", "enc.1.I", "enc.1.mab0.fc_q.weight", "enc.1.mab0.fc_q.bias", "enc.1.mab0.fc_k.weight", "enc.1.mab0.fc_k.bias", "enc.1.mab0.fc_v.weight", "enc.1.mab0.fc_v.bias", "enc.1.mab0.fc_o.weight", "enc.1.mab0.fc_o.bias", "enc.1.mab1.fc_q.weight", "enc.1.mab1.fc_q.bias", "enc.1.mab1.fc_k.weight", "enc.1.mab1.fc_k.bias", "enc.1.mab1.fc_v.weight", "enc.1.mab1.fc_v.bias", "enc.1.mab1.fc_o.weight", "enc.1.mab1.fc_o.bias", "dec.0.S", "dec.0.mab.fc_q.weight", "dec.0.mab.fc_q.bias", "dec.0.mab.fc_k.weight", "dec.0.mab.fc_k.bias", "dec.0.mab.fc_v.weight", "dec.0.mab.fc_v.bias", "dec.0.mab.fc_o.weight", "dec.0.mab.fc_o.bias", "dec.1.mab.fc_q.weight", "dec.1.mab.fc_q.bias", "dec.1.mab.fc_k.weight", "dec.1.mab.fc_k.bias", "dec.1.mab.fc_v.weight", "dec.1.mab.fc_v.bias", "dec.1.mab.fc_o.weight", "dec.1.mab.fc_o.bias", "dec.2.mab.fc_q.weight", "dec.2.mab.fc_q.bias", "dec.2.mab.fc_k.weight", "dec.2.mab.fc_k.bias", "dec.2.mab.fc_v.weight", "dec.2.mab.fc_v.bias", "dec.2.mab.fc_o.weight", "dec.2.mab.fc_o.bias", "dec.3.weight", "dec.3.bias". 
	Unexpected key(s) in state_dict: "encoder_decoder". 
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mlaced-pond-47[0m at: [34mhttps://wandb.ai/mashrafimonon-new-york-university/mof-settransformer/runs/aqpy7h9z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250816_145022-aqpy7h9z/logs[0m
